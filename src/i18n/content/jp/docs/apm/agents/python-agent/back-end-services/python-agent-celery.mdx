---
title: パイソンエージェントとセロリ
tags:
  - Agents
  - Python agent
  - Back-end services
metaDescription: How to record Celery background processes using the Python agent.
translationType: machine
---

Celeryを分散型タスクキューイングシステムとして使用している場合、Pythonエージェントを使用してCeleryのプロセスを [non-web transactions](/docs/apm/transactions/intro-transactions/monitor-background-processes-other-non-web-transactions) として記録することができます。

Celery で Python エージェントを動作させるには、まず [エージェントのインストール手順](/docs/agents/python-agent/installation-and-configuration/python-agent-installation) に従って、エージェントのインストール、設定、 [テスト](/docs/agents/python-agent/installation-and-configuration/testing-python-agent) を行います。その後、以下のCelery固有の手順を使用します。

## ラン・セロリ [#running-with-celery]

エージェントでCeleryを実行するために使用するコマンドは、Celeryのバージョンと特定のセットアップによって異なります。

<CollapserGroup>
  <Collapser
    id="run-celery-celery"
    title="セロリ"
  >
    `celery` コマンドを使用する場合は、カスタムオプションを含めてください。

    ```
    NEW_RELIC_CONFIG_FILE=<var>/some/path/</var>newrelic.ini newrelic-admin run-program celery <var>YOUR_COMMAND_OPTIONS</var>
    ```

    たとえば、

    ```
    NEW_RELIC_CONFIG_FILE=<var>/some/path/</var>newrelic.ini newrelic-admin run-program celery -A tasks worker --loglevel=info
    ```
  </Collapser>

  <Collapser
    id="run-celery-celeryd"
    title="Celeryd"
  >
    `celeryd` runコマンドは、Celeryの新しいリリースでは推奨されていません。まだ `celeryd` を使用する場合は、カスタムオプションを含めてください。

    ```
    NEW_RELIC_CONFIG_FILE=some/path/newrelic.ini newrelic-admin run-program celeryd <var>YOUR_COMMAND_OPTIONS</var>
    ```
  </Collapser>

  <Collapser
    id="run-celery-django"
    title="Django"
  >
    Djangoの管理コマンドでCeleryを起動する場合は、 `manage.py`. `celery` コマンドを Django のコマンドに置き換えて、カスタムオプションを含めてください。

    ```
    NEW_RELIC_CONFIG_FILE=<var>/some/path/</var>newrelic.ini newrelic-admin run-program python manage.py celery <var>YOUR_COMMAND_OPTIONS</var>
    ```
  </Collapser>

  <Collapser
    id="run-celery-initd"
    title="Initスクリプト"
  >
    Celeryの一般的なinitスクリプトを使用している場合は、スクリプトを編集して、スクリプトが使用されるときに呼び出される `celery` コマンドをラップします。このコマンドは通常次のようになります。

    ```
    CELERY_BIN=${CELERY_BIN:-"celery"}
    ```

    エージェントのラッパースクリプトを追加するには、 `CELERY_BIN` 変数を次のように変更します。ここで、 `some/path/` は、ファイルやパッケージへの実際のパスです。

    ```
    CELERY_BIN=${CELERY_BIN:-"NEW_RELIC_CONFIG_FILE=<var>/some/path</var>/newrelic.ini <var>/some/path</var>/bin/newrelic-admin run-program <var>/some/path</var>/bin/celery"}
    ```

    この変更により、 `CELERY_BIN` が呼び出されるたびに、実際の `celery` コマンドの周りにエージェントのラッパースクリプトが呼び出されるようになります。
  </Collapser>
</CollapserGroup>

## アプリケーション名の選択 [#selecting-the-application-name]

Python エージェント設定ファイルの `app_name` 設定は、New Relic One UI に表示されるアプリ名を設定します。

* PythonエージェントがCeleryのタスクをモニターしていて、 `app_name` をアプリケーションエージェントの `app_name` で使用されているのと同じ値に設定した場合、両方のソースからのデータはその名前でUIにまとめられます。
* 異なる名前を設定した場合、データは2つの異なる名前としてUIに別々に表示されます。

[エージェントの設定ファイルに複数のアプリ名を設定することで](/docs/agents/manage-apm-agents/app-naming/use-multiple-names-app) 、結合されたデータと分離されたデータの両方を監視することができます。ここでは、Django アプリケーションを例に、一般的な方法を紹介します。

<CollapserGroup>
  <Collapser
    id="multiple-app-names"
    title="複数のアプリケーション名の使用"
  >
    Djangoアプリを監視するエージェントには、次のように設定します。

    ```
    app_name = Your_app_name (Django); Your_app_name (Combined)
    ```

    Celeryを監視するエージェントには、次のように設定します。

    ```
    app_name = Your_app_name (Celery); Your_app_name (Combined)
    ```

    この結果、UIには3つの名前が表示されます。

    * `Your_app_name (Combined)` 、CeleryとDjangoアプリケーションの両方からのデータを組み合わせています。
    * `Your_app_name (Django)` 、Django のアプリデータを表示します。
    * `Your_app_name (Celery)` 、Celeryのデータを表示しています。
  </Collapser>
</CollapserGroup>

## タスク・リトライ・エラーの無視 [#ignoring-task-retry-errors]

Celery を使用している場合、タスクが失敗して `celery.exceptions:Retry` または `celery.exceptions:RetryTaskError` の例外が発生する可能性があります。この例外は、使用しているCeleryのバージョンによって異なります。

これらのエラーを無視するには、New Relic One の **Application settings** UI から、またはエージェントの config ファイルから設定します。UI での変更は、 [設定の優先順位ルール](/docs/agents/python-agent/installation-configuration/python-agent-configuration#options) により、設定ファイルの変更よりも優先されます。

エラーを無視する設定をUIから使用するため。

1. [one.newrelic.com](https://one.newrelic.com) から、 **APM> （選択したアプリ）> Settings> Application** を選択します。
2. 選択 **サーバーサイドエージェントの構成**.
3. **エラーコレクション** から、無視したいエラーをカンマで区切って入力します。

エージェントの設定ファイルを使ってこれらのエラーを無視するには、 [`ignore_errors`](/docs/agents/python-agent/installation-configuration/python-agent-configuration#error-ignore) の設定と、スペースで区切られた例外リストを使用します。

```
error_collector.ignore_errors = celery.exceptions:Retry celery.exceptions:RetryTaskError
```

## トラブルシューティング

Celeryワーカープロセスが突然終了すると、エージェントは通常のシャットダウンプロセスを完了することができず、最終的なデータペイロードが送信されません。その結果、エージェントから報告されるCeleryトランザクションの数が予想より少なくなるか、トランザクションが全く報告されなくなります。

これは、プールワーカープロセスが新しいワーカーに置き換えられるまでに実行できるタスクの最大数を定義する、 `CELERYD_MAX_TASKS_PER_CHILD` の設定を使用した場合に発生する可能性があります。この設定は、プールワーカープロセスが新しいワーカーに置き換えられるまでに実行できるタスクの最大数を定義します。この設定を使用すると、その制限に達したときにワーカーが強制的にシャットダウンされるため、そのデータはエージェントに記録されません。例えば、 `MAX_TASKS_PER_CHILD = 1` の場合、この結果、データは報告されません。

この問題をどのように解決するかは、アプリケーションで `MAX_TASKS_PER_CHILD` の制限を使用したい理由によって異なります。

* 通常のシャットダウンプロセスを許可するには、これをデフォルトのノーリミット設定に戻します。
* この問題の影響を少なくするために、 `MAX_TASKS_PER_CHILD` の制限値を上げてください。

<Callout variant="important">
  バージョン3.2.2.94以降では、 `MAX_TASKS_PER_CHILD` の制限に達した場合、Pythonエージェントはシャットダウンします。データは失われません。
</Callout>
