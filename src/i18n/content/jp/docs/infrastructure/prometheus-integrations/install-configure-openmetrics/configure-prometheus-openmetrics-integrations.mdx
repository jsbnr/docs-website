---
title: Prometheus OpenMetrics インテグレーションの設定
tags:
  - Integrations
  - Prometheus integrations
  - Install and configure OpenMetrics
metaDescription: Configuration options and examples for your Prometheus OpenMetrics integration with New Relic in Docker and Kubernetes environments.
translationType: machine
---

import dockerLogoCrop from 'images/docker-logo-crop.png'

import imgIntegrationK8S402X from 'images/img-integration-k8.png';

特に断りのない限り、Prometheus OpenMetricsとNew Relicとの統合のための設定オプションは、Docker環境とKubernetes環境の両方に適用されます。最低限、以下の設定値は **必須**:

* [ライセンスキー](/docs/apis/intro-apis/new-relic-api-keys/#ingest-license-key)
* [クラスター名](#definitions-configuration-file)

**推奨：** New Relic のライセンスキーを `LICENSE_KEY という環境変数として設定する` 。これにより、New Relic は [相互の TLS 認証秘密から環境変数を読み込むことができるため、より安全な環境を提供することができます](/docs/integrations/prometheus-integrations/install-configure/add-mutual-tls-prometheus-endpoints) 。

## nri-prometheus-latest.yamlの設定 [#general-config]

`nri-prometheus-latest.yaml` マニフェストファイルには、構成例を示す `nri-prometheus-cfg` マップが含まれています。マニフェストファイルを使用して、以下のパラメーターを設定します。

<CollapserGroup>
  <Collapser
    id="example-configuration-file"
    title="設定ファイルの例"
  >
    以下は構成ファイルの例で、保存して必要に応じて変更することができます。詳細については、 [相互TLS認証](/docs/integrations/prometheus-integrations/install-configure/add-mutual-tls-prometheus-endpoints) および [PromQLからNRQLへの変換](/docs/integrations/prometheus-integrations/view-query-data/translate-promql-queries-nrql) に関するドキュメントを参照してください。

    ```
    # The name of your cluster. It's important to match other New Relic products to relate the data.
    cluster_name: "<YOUR_CLUSTER_NAME>"

    # When standalone is set to false nri-prometheus requires an infrastructure agent to work and send data. Defaults to true
    # standalone: true

    # How often the integration should run. Defaults to 30s.
    # scrape_duration: "30s"

    # The HTTP client timeout when fetching data from targets. Defaults to 5s.
    # scrape_timeout: "5s"

    # How old must the entries used for calculating the counters delta be
    # before the telemetry emitter expires them. Defaults to 5m.
    # telemetry_emitter_delta_expiration_age: "5m"

    # How often must the telemetry emitter check for expired delta entries.
    # Defaults to 5m.
    # telemetry_emitter_delta_expiration_check_interval: "5m"

    # Wether the integration should run in verbose mode or not. Defaults to false.
    verbose: false

    # Whether the integration should run in audit mode or not. Defaults to false.
    # Audit mode logs the uncompressed data sent to New Relic. Use this to log all data sent.
    # It does not include verbose mode. This can lead to a high log volume, use with care.
    audit: false

    # Wether the integration should skip TLS verification or not. Defaults to false.
    insecure_skip_verify: false

    # The label used to identify scrapable targets. Defaults to "prometheus.io/scrape".
    scrape_enabled_label: "prometheus.io/scrape"

    # scrape_services Allows to enable scraping the service and not the endpoints behind.
    # When endpoints are scraped this is no longer needed
    scrape_services: true

    # scrape_endpoints Allows to enable scraping directly endpoints instead of services as prometheus service natively does.
    # Please notice that depending on the number of endpoints behind a service the load can increase considerably
    scrape_endpoints: false

    # Whether k8s nodes need to be labelled to be scraped or not. Defaults to true.
    require_scrape_enabled_label_for_nodes: true

    # Number of worker threads used for scraping targets.
    # For large clusters with many (>400) targets, slowly increase until scrape
    # time falls between the desired `scrape_duration`.
    # Increasing this value too much will result in huge memory consumption if too
    # many metrics are being scraped.
    # Default: 4
    # worker_threads: 4

    # Maximum number of metrics to keep in memory until a report is triggered.
    # Changing this value is not recommended unless instructed by the New Relic support team.
    # max_stored_metrics: 10000

    # Minimum amount of time to wait between reports. Cannot be lowered than the default, 200ms.
    # Changing this value is not recommended unless instructed by the New Relic support team.
    # min_emitter_harvest_period: 200ms

    # targets:
    #   - description: Secure etcd example
    #     urls: ["https://192.168.3.1:2379", "https://192.168.3.2:2379", "https://192.168.3.3:2379"]
    #     tls_config:
    #       ca_file_path: "/etc/etcd/etcd-client-ca.crt"
    #       cert_file_path: "/etc/etcd/etcd-client.crt"
    #       key_file_path: "/etc/etcd/etcd-client.key"

    # Proxy to be used by the emitters when submitting metrics. It should be
    # in the format [scheme]://[domain]:[port].
    # The emitter is the component in charge of sending the scraped metrics.
    # This proxy won't be used when scraping metrics from the targets.
    # By default it's empty, meaning that no proxy will be used.
    # emitter_proxy: "http://localhost:8888"

    # Certificate to add to the root CA that the emitter will use when
    # verifying server certificates.
    # If left empty, TLS uses the host's root CA set.
    # emitter_ca_file: "/path/to/cert/server.pem"

    # Set to true in order to stop autodiscovery in the k8s cluster. It can be useful when running the Pod with a service account
    # having limited privileges. Defaults to false.
    # disable_autodiscovery: false

    # Whether the emitter should skip TLS verification when submitting data.
    # Defaults to false.
    # emitter_insecure_skip_verify: false

    # Histogram support is based on New Relic's guidelines for higher
    # level metrics abstractions https://github.com/newrelic/newrelic-exporter-specs/blob/master/Guidelines.md.
    # To better support visualization of this data, percentiles are calculated
    # based on the histogram metrics and sent to New Relic.
    # By default, the following percentiles are calculated: 50, 95 and 99.
    #
    # percentiles:
    #   - 50
    #   - 95
    #   - 99

    # transformations:
    #   - description: "General processing rules"
    #     rename_attributes:
    #       - metric_prefix: ""
    #         attributes:
    #           container_name: "containerName"
    #           pod_name: "podName"
    #           namespace: "namespaceName"
    #           node: "nodeName"
    #           container: "containerName"
    #           pod: "podName"
    #           deployment: "deploymentName"
    #     ignore_metrics:
    #       # Ignore all the metrics except the ones listed below.
    #       # This is a list that complements the data retrieved by the New
    #       # Relic Kubernetes Integration, that's why Pods and containers are
    #       # not included, because they are already collected by the
    #       # Kubernetes Integration.
    #       - except:
    #         - kube_hpa_
    #         - kube_daemonset_
    #         - kube_statefulset_
    #         - kube_endpoint_
    #         - kube_service_
    #         - kube_limitrange
    #         - kube_node_
    #         - kube_poddisruptionbudget_
    #         - kube_resourcequota
    #         - nr_stats
    #     copy_attributes:
    #       # Copy all the labels from the timeseries with metric name
    #       # `kube_hpa_labels` into every timeseries with a metric name that
    #       # starts with `kube_hpa_` only if they share the same `namespace`
    #       # and `hpa` labels.
    #       - from_metric: "kube_hpa_labels"
    #         to_metrics: "kube_hpa_"
    #         match_by:
    #           - namespace
    #           - hpa
    #       - from_metric: "kube_daemonset_labels"
    #         to_metrics: "kube_daemonset_"
    #         match_by:
    #           - namespace
    #           - daemonset
    #       - from_metric: "kube_statefulset_labels"
    #         to_metrics: "kube_statefulset_"
    #         match_by:
    #           - namespace
    #           - statefulset
    #       - from_metric: "kube_endpoint_labels"
    #         to_metrics: "kube_endpoint_"
    #         match_by:
    #           - namespace
    #           - endpoint
    #       - from_metric: "kube_service_labels"
    #         to_metrics: "kube_service_"
    #         match_by:
    #           - namespace
    #           - service
    #       - from_metric: "kube_node_labels"
    #         to_metrics: "kube_node_"
    #         match_by:
    #           - namespace
    #           - node
    # integration definition files required to map metrics to entities
    # definition_files_path: /etc/newrelic-infra/definition-files
    ```
  </Collapser>

  <Collapser
    id="definitions-configuration-file"
    title="主な名称と定義"
  >
    ここでは、Prometheus OpenMetricsの設定ファイルの主要な名称と定義を紹介します。

    <table>
      <thead>
        <tr>
          <th style={{ width: "200px" }}>
            キーネーム
          </th>

          <th>
            説明
          </th>
        </tr>
      </thead>

      <tbody>
        <tr id="cluster-name">
          <td>
            `クラスター名`

            **必要です。**
          </td>

          <td>
            クラスターの名前です。この値は、すべてのメトリクスの `clusterName` 属性として含まれます。
          </td>
        </tr>

        <tr id="verbose">
          <td>
            `詳細`
          </td>

          <td>
            文字列化されたブーリアンです。

            * `真` （デフォルト）。デバッグ情報を記録します。
            * `false`: エラーメッセージのみを記録します。
          </td>
        </tr>

        <tr id="targets">
          <td>
            `ターゲット`
          </td>

          <td>
            インテグレーションによってスクレイピングされる静的エンドポイントの設定。オブジェクトのリストを含んでいます。この構造についての詳細は、 [target configuration](#target-config) に関するドキュメントを参照してください。
          </td>
        </tr>

        <tr id="scrape-enabled-label">
          <td>
            `scrape_enabled_label`

            <img style={{ width: '40px', height: '35px'}} class="inline" title="img-integration-k8.png" alt="img-integration-k8.png" src={imgIntegrationK8S402X}/> **Kubernetes**
          </td>

          <td>
            文字列です。統合は、Kubernetesポッドとサービスがアノテーションされているか、この値のラベルを持っているかどうかをチェックして、スクレイピングする必要があるかどうかを判断します。

            これは、メトリクスを無視したり、New Relic に送信される特定のメトリクスを含めたりして、データ量を制限したい場合に特に有効です。デフォルトでは、Prometheusがスクレイピング可能なターゲットを発見するために使用するのと同じラベルを使用しているので、インストールしたほとんどのエクスポーターは自動的にこのラベルを設定します。

            統合機能にスクレイプさせたいターゲットを細かく制御するには、このオプションを他の値に設定し（例えば、 `newrelic/scrape` ）、アノテーションまたはラベル `newrelic/scrape:"true"` をKubernetesオブジェクトに追加します。両方が設定されている場合は、アノテーションがラベルよりも優先されます。

            デフォルト： `" prometheus.io/scrape"`
          </td>
        </tr>

        <tr id="scrape-duration">
          <td>
            `scrape_duration`
          </td>

          <td>
            スクレーパーはどのくらいの頻度で稼働させればいいのでしょうか。

            * メモリ使用量を少なくするには、この値を大きくします。

            * メモリ使用量を増やすには、この値を減らします。

              メモリ使用量への影響は、すべてのデータを一度に照会（およびバッファリング）しないように、ターゲットのフェッチをスクレイプ間隔に分散させているためです。

              デフォルトは `30s` です。有効な値としては、 `1s`, `15s`, `30s`, `1m`, `5m` などがあります。
          </td>
        </tr>

        <tr id="scrape-timeout">
          <td>
            `scrape_timeout`
          </td>

          <td>
            エンドポイントからデータを取得する際のHTTPクライアントのタイムアウトです。

            デフォルト： `5s` 。有効な値は、 `1s`, `15s`, `30s`, `1m`, `5m`, などです。
          </td>
        </tr>

        <tr>
          <td>
            `worker_threads`
          </td>

          <td>
            ターゲットのスクレイピングに使用されるワーカースレッドの数。ターゲットの数が多い環境やレイテンシーの高いターゲットでは増やすことができますが、メモリ消費量が増える可能性があります。

            デフォルト： `4`.10以上の使用はお勧めしません。
          </td>
        </tr>

        <tr>
          <td>
            `require_scrape_enabled_label_for_nodes`

            ![img-integration-k8.png](.img-integration-k8.png "img-integration-k8.png") **Kubernetes**
          </td>

          <td>
            Kubernetesノードがスクレイピングにラベルを必要とするかどうか。

            デフォルト： `真`.
          </td>
        </tr>

        <tr id="percentiles">
          <td>
            `パーセンタイル`
          </td>

          <td>
            ヒストグラムのサポートは、 [New Relic's guidelines for higher level metrics abstractions](https://github.com/newrelic/newrelic-exporter-specs/blob/master/Guidelines.md) に基づいています。

            このデータの視覚化をより良くサポートするために、ヒストグラムのメトリクスに基づいてパーセンタイルが計算され、New Relic に送信されます。有効な値は、 `50` 、 `95` 、 `99` です。
          </td>
        </tr>

        <tr>
          <td id="emitter-proxy">
            `emitter_proxy`
          </td>

          <td>
            メトリクスを送信する際に統合が使用するプロキシ。

            `[scheme]://[domain]:[port].`

            このプロキシは、ターゲットからメトリクスを取得する際には使用されません。

            デフォルトでは、これは空で、プロキシは使用されません。
          </td>
        </tr>

        <tr>
          <td id="emitter-ca-file">
            `emitter_ca_file`
          </td>

          <td>
            エミッタがサーバ証明書を検証する際に使用するルートCAに追加する証明書。空の場合、TLSはホストのルートCAセットを使用する。
          </td>
        </tr>

        <tr id="emitter-insecure-skip-verify">
          <td>
            `emitter_insecure_skip_verify`
          </td>

          <td>
            エミッターがデータを送信する際にTLS検証をスキップするかどうか。デフォルト： `false`.
          </td>
        </tr>

        <tr id="disable-autodiscovery">
          <td>
            `ディセーブルオートディスカバリー`
          </td>

          <td>
            k8sクラスターでの自動検知を無効にするために、trueに設定します。この設定は、限られた権限を持つサービスアカウントでPodを実行する場合に便利です。デフォルト： `false`.
          </td>
        </tr>
      </tbody>
    </table>
  </Collapser>
</CollapserGroup>

## ターゲットキーにオブジェクトを設定 [#target-config]

設定ファイルのターゲットキーに1つ以上のオブジェクトを含める場合は、YAMLリストに以下の構造を使用します。

<table>
  <thead>
    <tr>
      <th style={{ width: "250px" }}>
        キーネーム
      </th>

      <th>
        説明
      </th>
    </tr>
  </thead>

  <tbody>
    <tr id="description">
      <td>
        `説明`
      </td>

      <td>
        このターゲット内のURLの説明です。
      </td>
    </tr>

    <tr id="urls">
      <td>
        `urls`
      </td>

      <td>
        スクレイピングされるURLを含む文字列のリスト。
      </td>
    </tr>

    <tr id="tls-config">
      <td>
        `tls_config`
      </td>

      <td>
        リクエストを送信する際に使用する認証設定です。TLSとMutual TLSに対応しています。詳細は、 [相互TLS認証に関するドキュメント](/docs/integrations/prometheus-integrations/install-configure/add-mutual-tls-prometheus-endpoints) を参照してください。
      </td>
    </tr>
  </tbody>
</table>

<CollapserGroup>
  <Collapser
    id="specify-path-port"
    title={<><img src={imgIntegrationK8S402X} title="img-integration-k8s@2x.png" alt="img-integration-k8s@2x.png" style={{ height: '35px', width: '40px' }}/>Kubernetesのポートとエンドポイントのパス</>}
  >
    New Relic の Prometheus OpenMetrics 統合は、スクレイピングするターゲットを自動的に発見します。ターゲットを構築する際に使用するポートとエンドポイントのパスを指定するには、 `prometheus.io/port` と `prometheus.io/path` のアノテーションまたはラベルを、Kubernetes のポッドやサービスで使用します。アノテーションはラベルよりも優先されます。

    * `prometheus.io/port` が存在しない場合、統合はサービスに定義された各 `port` または `ContainerPort` をスクレイプしようとします。
    * `prometheus.io/path` が存在しない場合、統合のデフォルトは `/metrics` となります。
    * サービスがデフォルトの `/my-metrics-path` パスで実行されていない場合は、ポッドにラベルを追加します `prometheus.io/path=my-metrics-path` 。メトリクスエンドポイントへのパスがより複雑で、有効なラベル値にできない場合（例えば、 `foo/bar` ）、代わりにアノテーションを使用します。
  </Collapser>

  <Collapser
    id="example-port-path"
    title={<><img src={imgIntegrationK8S402X} title="img-integration-k8s@2x.png" alt="img-integration-k8s@2x.png" style={{ height: '35px', width: '40px' }}/>例。Kubernetesのポートとパスのラベル</>}
  >
    この例では、クラスター内にデプロイメントがあり、ポッドがポート `8080` とパス `my-metrics でPrometheusメトリクスを公開しています。`

    デプロイメントマニフェストの `PodSpec` metadata で、ラベル `prometheus.io/port:"8080"` と `prometheus.io/path:"my-metrics"` を設定します。インテグレーションがポッドからメトリクスを取得しようとすると、 `http://<pod-ip>:8080/my-metrics` にリクエストを送信します。

    ```
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: my-deployment
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: my-app
      template:
        metadata:
          labels:
            app: my-app
            prometheus.io/scrape: "true"
            prometheus.io/port: "8080"
            prometheus.io/path: "my-metrics"
    ```
  </Collapser>
</CollapserGroup>

## サービスとエンドポイントのスクレイプ動作

デフォルトでは、 `scrape_services` が `true` に、 `scrape_endpoints` が `false` に設定されているため、サービスは基礎となるエンドポイントではなく直接スクレイピングされます。

この動作を変更するには、 `scrape_endpoints` を `true` configuring `Prometheus OpenMetrics integrations` を設定することで、サービスを直接スクレイピングするのではなく、Prometheus server がネイティブに行うように、基礎となるエンドポイントをスクレイピングすることができます。

クラスタ内のサービスの背後にあるエンドポイントの数に応じて、負荷と取り込まれるデータが大幅に増加する可能性があることに留意し、監視し、必要に応じてリソース要件を増加させてください。

さらに、 `scrape_services` と `scrape_endpoints` の両方をtrueに設定して逆互換性を保証することが可能であったとしても、データの重複を招くことになります。

## 設定の再読み込み [#reload-config]

Prometheus OpenMetrics integration **は、設定ファイルに変更を加えたときに** 自動的に設定を再読み込みしません。

<img style={{ width: '40px', height: '35px'}} class="inline" title="Docker アイコン" alt="Docker アイコン" src={dockerLogoCrop}/> **Docker:**

設定を再読み込みするには、統合を実行しているコンテナを再起動します。

```
docker restart nri-prometheus
```

<img style={{ width: '40px', height: '35px'}} class="inline" title="img-integration-k8.png" alt="img-integration-k8.png" src={imgIntegrationK8S402X}/> **Kubernetes:**

設定を再読み込みするには、統合を再起動してください。 **推奨：** 配置をスケールダウンしてレプリカが0個になってから、スケールダウンしてレプリカが1個になるようにしてください。

```
kubectl scale deployment nri-prometheus --replicas=0
kubectl scale deployment nri-prometheus --replicas=1
```

## Dockerです。以前の設定ファイルの実行 [#run-previous]

<img style={{ width: '40px', height: '35px'}} class="inline" title="Docker アイコン" alt="Docker アイコン" src={dockerLogoCrop}/> **Docker:** 先ほどの設定ファイルで統合を実行するため。

1. その内容をコピーして、 `config.yaml` ファイルに保存します。

2. 同じディレクトリ内で、コマンドを実行します。

   ```
   docker run -d --restart unless-stopped \
       --name nri-prometheus \
       -e CLUSTER_NAME="<var>YOUR_CLUSTER_NAME</var>" \
       -e LICENSE_KEY="<var>YOUR_LICENSE_KEY</var>" \
       -v "$(pwd)/config.yaml:/config.yaml" \
       newrelic/nri-prometheus:latest --configfile=/config.yaml
   ```
