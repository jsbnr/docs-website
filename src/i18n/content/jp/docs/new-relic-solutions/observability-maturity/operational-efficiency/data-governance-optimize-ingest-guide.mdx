---
title: インジェストデータを最適化する
tags:
  - Observability maturity
  - Operational efficiency
  - Data ingest cost
  - Data governance
  - Sampling rate
  - Drop rules
  - Observability as code
  - Value drivers
  - Bill and Usage Data
  - Data ingest cost
metaDescription: Data governance is a practice of ensuring optimal value for telemetry data collected by an organization particularly a complex organization with numerous business units and working groups.
translationType: machine
---

import optimizingicon from 'images/oma-oe-dg-optimizing-icon.png'

import valuedriversuptime from 'images/oma-oe-dg-value-driver-uptime.png'

import valuedriverscustomer from 'images/oma-oe-dg-value-driver-customer.png'

import valuedriversinnovation from 'images/oma-oe-dg-value-driver-innovation.png'

import kubestatemetrics from 'images/oma-oe-dg-update-k8s-kube-state-metrics.png'

import kubernetesscrapeinterval from 'images/oma-oe-dg-update-k8s-scrape-interval.png'

<img
  src={optimizingicon}
  alt="Optimize"
  style={{ height: '96px', width: '120px', verticalAlign: 'middle', horizontalAlign: 'right'}}
/>

## 望ましい結果 [#desired-outcome]

データインジェストを最適化することにより、データの観測可能な価値を最大化します。不要なインジェストデータを削減し、予算内に収まるようにします。

## プロセス [#process]

[観測可能な目標に優先順位をつける](#prioritize-objectives)  
[最適化計画を立てる](#develop-plan)  
[データ削減技術を使用して計画を実行する。](#use-reduction-techniques)

### 観測可能な目標に優先順位をつける [#prioritize-objectives]

データガバナンスのフレームワークの最も重要な部分の1つは、収集したテレメトリを _observability value drivers_ と整合させることです。新しいテレメトリを設定する際には、主要な観測可能性の目的が何であるかを確実に理解する必要があります。

新しい遠隔測定を導入する場合、それが観測可能なソリューション全体に何をもたらすかを理解する必要があります。新しいデータは他のデータと重なるかもしれません。もし、どの重要な目的にも合致しないテレメトリーを導入するのであれば、そのデータの導入は再考する必要があるかもしれません。

目的は以下の通りです。

* 社内SLAを満たす
* 外部SLAを満たす
* 機能革新の支援（A/Bパフォーマンス& 採用テスト）
* カスタマーエクスペリエンスのモニター
* ベンダーと社内サービスプロバイダのSLAを遵守する
* ビジネスプロセスのヘルスモニタリング
* その他のコンプライアンス要件

これらの目標に沿うことで、あるデータセットを別のデータセットよりも優先させるという柔軟かつ直感的な判断が可能になり、新しいプラットフォームやサービスのインストルメント化を行う際に、どこから手をつければよいのか、チームのガイド役を務めることができます。

### 最適化プランの策定 [#develop-plan]

このセクションでは、2つの核となる仮定を設定します。

* [Baseline your data ingest](/docs/new-relic-solutions/observability-maturity/operational-efficiency/dg-baselining) セクションにあるツールやテクニックを使って、私たちのインセッ トがどこから来たのか、きちんと把握することができます。
* [observability maturity value drivers](https://docs.newrelic.com/docs/new-relic-solutions/observability-maturity/introduction/) についてよく理解していること。これは、テレメトリのグループに価値と優先度を適用する際に、非常に重要になります。

以下の例は、テレメトリーインジェストをどのように評価し、予算内に収めるために必要な、時には難しい決断を下すかをイメージするのに役立ちます。これらの例はそれぞれバリュードライバーに焦点を当てようとしていますが、ほとんどのインスツルメンテーションは1つ以上のバリュードライバーに貢献しています。これはデータインジェストガバナンスの最も難しい部分です。

<CollapserGroup>
  <Collapser
    id="case-study-1"
    title="例1．稼働率・信頼性の重視"
  >
    アカウントは、予算よりも約20％多く取り込みます。彼らはマネージャーから消費を減らす方法を見つけるように頼まれました。彼らの最も重要なバリュードライバーは `Uptime, performance, and reliability`

    <img
      src={valuedriversuptime}
      alt="Observability value drivers with a focus on Uptime and Reliability"
      title="Observability value drivers with a focus on Uptime and Reliability"
      style={{width: "400px"}}
    />

    <figcaption>
      **稼働時間と信頼性に重点を置いた可**観測性バリュードライバー
    </figcaption>

    彼らの遺産は以下の通りです。

    * APM (dev、staging、prod)

    * ディストリビューティッド（分散）トレーシング

    * ブラウザ

    * インフラ監視 100ホスト

    * K8sのモニタリング（dev, staging, prod）

    * ログ（dev, staging, prod - debugを含む）

      <Callout
        variant="IMPORTANT"
        title="最適化計画"
      >
        * デバッグログを省略する（問題がある場合はオンにできることを承知で）（5%節約できる）
        * Kubernetesクラスターエクスプローラーを表示するために必要のないいくつかのK8s状態メトリックを省略します（10％節約）
        * 新機能のA/Bテストを多く行っていた頃に収集していたカスタムブラウザのイベントを削除（10%節約可能）
      </Callout>

      これらの変更を実行した後、チームは予算を5％下回るようになり、NPMパイロットを実行するためのスペースが解放されました。彼らのマネージャーは、重要な`Uptime and reliability`の可観測性を失っていないことに満足しています。

      <Callout
        variant="IMPORTANT"
        title="最終結果"
      >
        * 当初予算より5%減
        * アップタイム、パフォーマンス、信頼性の目標を達成するためのNPMパイロットのためのヘッドルームを作成しました。
        * アップタイムと信頼性の観測可能性の最小限の損失
      </Callout>
  </Collapser>

  <Collapser
    id="case-study-2"
    title="例2:カスタマーエクスペリエンスへの注力"
  >
    モバイルモニタリングとブラウザモニタリングに重点を置いた新しいユーザー向けプラットフォームを担当するチームは、予算を50％上回っています。取り込みのサイズを適切に設定する必要がありますが、 `Customer Experience`の可観測性を犠牲にしないことに固執しています。

    <img
      src={valuedriverscustomer}
      alt="Observability value drivers with a focus on Customer Experience"
      title="Observability value drivers with a focus on Customer Experience"
      style={{width: "400px"}}
    />

    <figcaption>
      **カスタマーエクスペリエンス**に焦点を当てた可観測性バリュードライバー
    </figcaption>

    彼らの遺産は以下の通りです。

    * モバイル

    * ブラウザ

    * APM

    * ディストリビューティッド（分散）トレーシング

    * プロセスサンプルを含む30台のホスト上のインフラ

    * バックエンドの非同期プロセスのサーバーレス監視

    * そのサーバーレス機能からのログ

    * 各種クラウドインテグレーション

      <Callout
        variant="IMPORTANT"
        title="最適化計画"
      >
        * サーバーレスのログを省略する（基本的にLambdaとの連携で得られるものと冗長になっている）
        * そのホストのプロセスのサンプルレートを1分ごとに減少させる
        * DEV環境でのサンプルデータのドロップ処理
        * New Relic infra agentが提供する他のインフラ監視と冗長性が高いEC2統合をオフにする。
      </Callout>

      <Callout
        variant="IMPORTANT"
        title="最終結果"
      >
        * 当初予算より5％オーバー
        * 繁忙期を乗り切るには十分な量です。
        * 顧客体験の観測可能性を損なわない
      </Callout>

      その結果、当初の予算を5％上回っただけで、ピークシーズンを乗り切るには十分であると結論づけた。
  </Collapser>

  <Collapser
    id="case-study-3"
    title="例3：イノベーションへの注力"
  >
    あるチームが、大規模なPythonモノリスを4つのマイクロサービスにリファクタリングしている最中です。モノリスは、顧客データベースやキャッシュレイヤーなど、多くのインフラを新しいアーキテクチャと共有しています。彼らは予算を70%超過しており、モノリスを正式に廃止するまであと2ヶ月しかない。

    <img
      src={valuedriversinnovation}
      alt="Observability value drivers with a focus on Innovation and Growth"
      title="Observability value drivers with a focus on Innovation and Growth"
      style={{width: "400px"}}
    />

    <figcaption>
      **イノベーションと成長**に焦点を当てた可観測性の価値ドライバー
    </figcaption>

    彼らの遺産は以下の通りです。

    * K8sの監視（マイクロサービス）

    * New Relic ホスト監視 (monolith)

    * APM（マイクロサービス、ホスト監視）

    * 分散トレース(マイクロサービス、ホスト監視)

    * Postgresql（共有）

    * Redis(共有)

    * MSSQL (マイクロサービスアーキテクチャのための将来のDB)

    * ロードバランサーのログ取得（マイクロサービス、ホスト監視）

      <Callout
        variant="IMPORTANT"
        title="最適化計画"
      >
        * ロードバランサーのログを5xxレスポンスコードのみ監視するように設定する（monolith）
        * モノリスが動作しているホストのProcessSample, StorageSample, NetworkSampleのサンプルレートを60sにカスタマイズしました。
        * 現在、新しいアーキテクチャではMSSQLを使用していないため、MSSQLの監視を無効にします。
        * モノリスの分散トレースは、マイクロサービスアーキテクチャではあまり役に立たないので、無効にしてください。
      </Callout>

      <Callout
        variant="IMPORTANT"
        title="最終成果"
      >
        * 当初予算を1％下回る
        * イノベーションの観測可能性を損なわない
      </Callout>
  </Collapser>
</CollapserGroup>

<Callout variant="tip">
  使い慣れたタスク管理ツールで計画を追跡することをお勧めします。これは、最適化計画を管理し、各最適化タスクがもたらす効果を理解するのに役立ちます。この [データ最適化計画テンプレート](https://docs.google.com/spreadsheets/d/1CimLpALwl1Z9f41vzbNWx00bGcED9XPV3s4ROqVEnr0/copy)を使用できます。
</Callout>

### データ削減のテクニックを使って、計画を実行する [#use-reduction-techniques]

この段階では、アカウントにあるすべての種類の遠隔測定と、それらがどのようにバリュードライバーに関連するかについて考えています。このセクションでは、様々な種類の遠隔測定をどのように削減するかについて、詳細な技術的説明と例を提供します。さまざまなアプローチ

<CollapserGroup>
  <Collapser
    id="optimization-through-configuration"
    title="コンフィギュレーションによる最適化"
  >
    <CollapserGroup>
      <Collapser
        id="apm-agent"
        title="APMエージェント"
      >
        <Callout
          variant="IMPORTANT"
          title="成長ドライバー"
        >
          * 監視対象取引
          * エラー活動
          * カスタムイベント
        </Callout>

        APMエージェントが生成するデータ量は、いくつかの要因によって決定される。

        * アプリケーションによって生成されたオーガニックトラフィックの量（つまり、すべての条件が同じであれば、1日に100万回呼び出されるアプリケーションは、1日に1000回呼び出されるアプリケーションよりも多くのデータを生成します）。

        * 基礎となるトランザクションデータ自体のいくつかの特徴（URLの長さと複雑さ）

        * アプリケーションがデータベースクエリーを報告しているかどうか

        * アプリケーションに多くの（または任意の）カスタム属性を持つトランザクションがあるかどうか

        * アプリケーションのエラー量

        * アプリケーションエージェントが分散トレース用に設定されているかどうか

          ### 容量の管理

          アプリケーションへの呼び出しはすべてビジネスをサポートするために必要であると考えることができますが、アーキテクチャ全体ではもっと倹約できる可能性があります。極端な例では、クライアントから10秒ごとに呼び出されるユーザープロファイルマイクロサービスを持つことができます。これは、一部のユーザー情報が他のクライアントによって更新された場合に、レイテンシーを減らすのに役立ちます。しかし、私たちは、このサービスの呼び出し頻度を、例えば1分ごとに減らすことも一つの手段だと考えています。

          ### カスタムアトリビュート

          APM API [addCustomParameter](https://developer.newrelic.com/collect-data/custom-attributes/) の呼び出しを使用して追加された [カスタム属性は](/docs/data-apis/custom-data/custom-events/collect-custom-attributes/)、トランザクションペイロードに追加属性を追加する。これらはしばしば有用であるが、アプリケーションのロジックや優先順位が変わると、データの価値が低下したり、時代遅れになることもある。

          Javaエージェントは、デフォルトで以下のrequest.headerをキャプチャします。

        * request.headers.referer

        * request.headers.accept

        * request.headers.contentLength

        * request.headers.host

        * request.headers.userAgent

          開発者は、 `addCustomParameter`を使用して追加の（場合によってはより詳細なヘッダー）をキャプチャすることもできます。

          APMに関連する豊富な設定の例については、 [Javaエージェントのドキュメントをご覧ください。](/docs/apm/agents/java-agent/attributes/java-agent-attributes/#requestparams)

          ### エラーイベント

          APMでエラーがどのように処理されるかを決定することが可能である。これにより、場合によってはデータ量を減らすことができる。例えば、量は多いが無害なエラーがあり、現時点では削除できない場合があります。

          `collect` 、 `ignore` 、または`mark as expected`の機能があります。このドキュメントは[すべての詳細を](/docs/apm/agents/manage-apm-agents/agent-data/manage-errors-apm-collect-ignore-or-mark-expected/)カバーしています。

          ### データベースクエリ

          APMインスタンスで大きく変動するのは、データベースの呼び出し回数と、どのような設定をしたかという点です。データベースクエリの監視をどの程度冗長にするかは、かなりコントロールできます。これらのクエリは、トランザクショントレースページに表示されます。

          一般的なデータベースクエリの設定変更は以下の通りです。

        * [難読化されたクエリデータではなく、生のクエリデータを収集する、またはクエリの収集をオフにする](/docs/apm/transactions/transaction-traces/configure-transaction-traces#record-sql)

        * スタックトレースの閾値の変更

        * クエリの説明プラン収集をオンにする

          [詳しくはこちら](docs/apm/transactions/transaction-traces/transaction-traces-database-queries-page/#settings)。

          ### イベント制限の設定

          APMとモバイルエージェントには、収穫サイクルごとに報告できるイベントの数に制限があります。制限がない場合、送信されるイベントの数が非常に多いと、アプリケーションまたはNewRelicのパフォーマンスに影響を与える可能性があります。制限に達すると、エージェントは、収穫サイクル全体のイベントの代表的なサンプルを提供するために、イベントのサンプリングを開始します。エージェントが異なれば、制限も異なります。

          キャップされ、サンプリングの対象となるイベントは以下の通りです。

        * エージェントAPIを介して報告されたカスタムイベント（たとえば、.NETエージェントの`RecordCustomEvent` ）

        * モバイル

        * MobileCrash

        * MobileHandledException

        * MobileRequest

        * スパン（分散トレースサンプリングを参照）

        * トランザクション

        * TransactionError

          ほとんどのエージェントには、サンプリングされたトランザクションのイベント制限を変更するための構成オプションがあります。たとえば、Javaエージェントは[max_samples_stored](https://docs.newrelic.com/docs/agents/java-agent/configuration/java-agent-configuration-config-file#ae-max_samples_stored)を使用します。 _max_samples_stored_のデフォルト値は`2000`で、最大値は`10000`です。この値は、エージェントインスタンスから60秒ごとに報告できるサンプリングされたイベントの数を示します。

          ここでは、 [イベントのサンプリング制限](https://docs.newrelic.com/docs/using-new-relic/data/understand-data/new-relic-event-limits-sampling/)の完全な説明を示します

          [NRQLの`EXTRAPOLATE`演算子](/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions/#extrapolate)を使用して、サンプリングされたイベントを補正できます。

          サンプリングの方法を変更する前に、以下の注意点と推奨事項をお読みください。

        * レポートするイベントが多いほど、エージェントが使用するメモリも多くなります。

        * 通常、エージェントのイベントレポートの制限を上げることなく、必要なデータを取得できます。

        * ペイロードサイズの制限は1MB（10 ^ 6バイト）（圧縮）であるため、イベントの数は引き続きその制限の影響を受ける可能性があります。イベントがドロップされているかどうかを確認するには、エージェントログで`413 HTTP`ステータスメッセージを確認してください。

          ### トランザクショントレース

          <Callout
            variant="IMPORTANT"
            title="成長ドライバー"
          >
            * 接続サービス数
            * 接続サービスごとの監視対象メソッドコール数
          </Callout>

          APM では、 [トランザクショントレース](/docs/apm/transactions/transaction-traces/transaction-traces) は、アプリケーションのトランザクションとデータベースコールに関する詳細な情報を記録します。トランザクショントレースのデフォルト設定を編集することができます。これは、 [このガイド](/docs/apm/transactions/transaction-traces/configure-transaction-traces) を使って高度に設定可能です。設定可能なレベルやモードは、多くの場合、言語固有です。

          サーバーサイドの設定を使用して利用できるトランザクショントレースの設定は、使用するNew Relicエージェントによって異なります。UI には、それぞれの説明が記載されています。UI での設定には、以下のものが含まれる場合があります。

        * トランザクショントレーシングと閾値

        * 記録レベルと入力フィールドなどの、SQLを記録する

        * SQLとスタックトレースの閾値をログする

        * SQLクエリプランと閾値

        * HTTPコードとエラークラスなどの、エラーの収集

        * 遅いクエリのトレース

        * スレッドプロファイラー

        * クロスアプリケーショントレーシング

          ### ディストリビューティッド（分散）トレーシング

          分散トレースの設定には、言語固有の違いがあります。

          分散トレースは、必要に応じて無効にすることができます。これはJavaエージェントの例です `newrelic.yml`

          ```
          distributed_tracing:
              enabled: false
          ```

          これはnode.jsの例です `newrelic.js`

          ```
          distributed_tracing: {
            enabled: false
          }
          ```

          データ量は、[無限トレース](/docs/distributed-tracing/infinite-tracing/introduction-infinite-tracing/)を使用しているかどうかによっても異なります。

          APMエージェント（上）の標準ディストリビューティッド（分散）トレーシングはトレースの最大10%を取得しますが、すべてのデータを分析し、最も関連のあるトレースを検索すると、無限トレーシングを設定できます。この標準ディストリビューティッド（分散）トレーシングの代替は、C SDKを除く、すべてのAPM言語エージェントに使用できます。

          月間の摂取量を少しでも増やすための主なパラメータは以下の通りです。

        * トレースオブザーバモニタリングの設定

        * span属性トレースフィルターの設定

        * ランダムトレースフィルターの設定
      </Collapser>

      <Collapser
        id="browser-agent"
        title="Browserエージェント"
      >
        <Callout
          variant="IMPORTANT"
          title="成長ドライバー"
        >
          * ページロード
          * Ajaxコール
          * エラー活動
        </Callout>

        [エージェントバージョン 1211](/docs/release-notes/new-relic-browser-release-notes/browser-agent-release-notes/) 以降では、ページが行うすべてのネットワークリクエストは、AjaxRequest イベントとして記録されます。アプリケーション設定ページの拒否リスト設定オプションを使用して、イベントを記録するリクエストをフィルタリングすることができます。このフィルタに関係なく、すべてのネットワーク要求はメトリクスとしてキャプチャされ、AJAXページで利用できます。

        ### 拒否リストの使用

        リクエストは3つの方法でブロックされます。

        * すべての`AjaxRequest`イベントの記録をブロックするには、ワイルドカードとしてアスタリスク\*を追加します。

        * ドメインへの`AjaxRequest`イベントの記録をブロックするには、ドメイン名のみを入力します。例： `example.com`

        * 特定のドメインとパスへの`AjaxRequest`イベントの記録をブロックするには、ドメインとパスを入力します。例： `example.com/path`

        * 拒否リストでは、URLのプロトコル、ポート、サーチ、ハッシュは無視されます。

          拒否リストでは、URLのプロトコル、ポート、サーチ、ハッシュは無視されます。

          追加したフィルタが期待通りに動作するかどうかを検証するために、フィルタにマッチするAjaxRequestイベントのNRQLクエリを実行します。

          ### 拒否リストにアクセスする

          アプリケーションがイベント作成時にフィルタリングするURLの拒否リストを更新するには、アプリの設定ページに移動します。

          [one.newrelic.com](http://one.newrelic.com/) にアクセスし、「ブラウザー」をクリックします。アプリを選択します。左側のナビゲーションで、 _アプリ設定_ をクリックします。 _Ajax request deny list_ の下に、アプリに適用するフィルタを追加します。 _Save application settings_ を選択し、エージェント設定を更新します。ブラウザエージェントを再展開します（関連する APM エージェントを再起動するか、コピー/貼り付けのブラウザインストールを更新します）。

          ### バリデーション

          ```
          FROM AjaxRequest SELECT * WHERE requestUrl LIKE `%example.com%`
          ```
      </Collapser>

      <Collapser
        id="mobile-agent"
        title="モバイルエージェント"
      >
        <Callout
          variant="IMPORTANT"
          title="成長ドライバー"
        >
          * 月間アクティブユーザー数
          * クラッシュイベント
          * ユーザーごとのイベント数
        </Callout>

        ### Android

        [機能フラグ](/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/android-agent-configuration-feature-flags/)

        エージェントを起動するための呼び出しを含むすべての設定は、MainActivityクラスのonCreateメソッドで呼び出されます。設定を変更するには、2つの方法のうちの1つで呼び出します（設定がサポートしている場合）。

        ```
        NewRelic.disableFeature(FeatureFlag.DefaultInteractions);
        NewRelic.enableFeature(FeatureFlag.CrashReporting);
        NewRelic.withApplicationToken(<NEW_RELIC_TOKEN>).
        start(this.getApplication());
        ```

        [分析設定](/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/android-agent-configuration-feature-flags#analytics-settings)は、イベントデータの収集を有効または無効にします。これらのイベントはNewRelicデータベースに報告され、**クラッシュ分析**ページで使用されます。

        [エージェントのログ](/docs/mobile-monitoring/new-relic-mobile-android/android-sdk-api/android-agent-configuration-feature-flags#logging-settings-logging)を多かれ少なかれ冗長になるように構成することもできます。

        ### iOS

        Android と同様に、New Relic の iOS 設定では、機能フラグの有効化と無効化を行うことができます。

        以下の機能フラグを設定することができます。

        #### クラッシュとエラーの報告

        * NRFeatureFlag_CrashReporting
        * NRFeatureFlag_HandleExceptionEvents
        * NRFeatureFlag_CrashReporting

        #### ディストリビューティッド（分散）トレーシング

        * NRFATUREFLAG_DistributedTracing

        #### 相互作用

        * NRFeatureFlag_DefaultInteractions
        * NRFureFlag_InteractionTracing
        * NRFureFlag_SwiftInteractionTracing

        #### ネットワーク機能フラグ

        * NRFeatureFlag_ExperimentalNetworkInstrumentation
        * NRFeatureFlag_NSURLSessionInstrumentation
        * NRFeatureFlag_NetworkRequestEvents
        * NRFeatureFlag_RequestErrorEvents
        * NRFeatureFlag_HttpResponseBodyCapture

        [詳細](/docs/mobile-monitoring/new-relic-mobile-ios/ios-sdk-api/ios-agent-configuration-feature-flags/)については、このドキュメントを参照してください。
      </Collapser>

      <Collapser
        id="infrastructure-agent"
        title="インフラストラクチャー・エージェント"
      >
        <Callout
          variant="IMPORTANT"
          title="成長ドライバー"
        >
          * ホストとコンテナの監視
          * コアイベントのサンプリングレート
          * プロセスサンプル構成
          * カスタムアトリビュート
          * インストールされているオンホストインテグレーションの数および種類
          * ログ転送の設定
        </Callout>

        New Relic の [Infrastructure エージェント設定ファイル](/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/) には、インジェスト量を制御するための強力な方法がいくつか含まれています。最も重要なのは、サンプリング レートを使用することです。使用できるサンプリングレートの構成はいくつかあります。もうひとつは、カスタムプロセスサンプルフィルタを使用する方法です。

        ### サンプリングレート

        インフラストラクチャで設定可能なサンプリングレートは多数ありますが、最も一般的に使用されるのはこれらのレートです。

        | パラメータ                                            | デフォルト | 無効化 |
        | ------------------------------------------------ | ----- | --- |
        | メトリクス・ストレージ・サンプル・レート（metrics_storage_sample_rate | 5     | -1  |
        | メトリクス・プロセス・サンプル・レート（metrics_process_sample_rate  | 20    | -1  |
        | metrics_network_sample_rate                      | 10    | -1  |
        | メトリクス・システム・サンプル・レート（metrics_system_sample_rate   | 5     | -1  |
        | Metrics_nfs_sample_rate                          | 5     | -1  |

        ### プロセスサンプル

        プロセスサンプルは、インフラストラクチャーエージェントからの最も大量なデータソースとなり得ます。これは、ホスト上で実行中のあらゆるプロセスに関する情報を送信するためです。これらはデフォルトでは無効になっていますが、以下のように有効化することができます。

        ```
        enable_process_metrics: true
        ```

        これは、 `metrics_process_sample_rate`を-1に設定するのと同じ効果があります。

        デフォルトでは、メモリ不足のプロセスはサンプリングから除外されます。詳細については、 `disable-zero-mem-process-filter`を参照してください。

        `include_matching_metrics`を設定することで、New Relicに送信されるデータの量を制御できます。これにより、メトリック[属性](/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/query-infrastructure-dimensional-metrics-nrql#naming-conventions)の値に基づいてメトリックデータの送信を制限できます。

        メトリックの属性のいずれかにリテラル値または部分値を定義することで、メトリックデータを含めることができます。例えば、process.name が ^java 正規表現に一致するすべてのプロセスの host.process.cpuPercent を送信するよう選択できます。

        この例では、実行ファイルと名前を使ってプロセスメトリクスを含めています。

        ```
        include_matching_metrics: # You can combine attributes from different metrics
            process.name:
              - regex “^java”    # Include all processes starting with "java"
            process.executable:
              - “/usr/bin/python2”              # Include the Python 2.x executable
              - regex “\\System32\\svchost”     # Include all svchost executables
        ```

        また、このフィルターはKubernetesの統合にも使用できます。

        ```
        env:
            - name: NRIA_INCLUDE_MATCHING_METRICS
              value: |
                process.name:
                  - regex "^java"
                process.executable:
                  - "/usr/bin/python2"
                  - regex "\\System32\\svchost"
        ```

        ### ネットワークインターフェースフィルタ

        <Callout
          variant="IMPORTANT"
          title="成長ドライバー"
        >
          * 監視するネットワーク・インターフェース数
        </Callout>

        この設定では、シンプルなパターンマッチングメカニズムを使用しており、いずれかのパターンに続く特定の文字または数字のシーケンスで始まるインターフェースを探すことができます。

        * `{name}[other characters]`
        * `[number]{name}[other characters]` 、ここで`index-1`オプションを使用して名前を指定します

        ```
        network_interface_filters:
          prefix:
            - dummy
            - lo
          index-1:
            - tun
        ```

        Linuxのデフォルトのネットワークインターフェイスフィルタ。

        * `dummy` 、 `lo` 、 `vmnet` 、 `sit` 、 `tun` 、 `tap` 、または `veth`
        * `tun`またはを含むネットワークインターフェース `tap`

        Windowsのデフォルトのネットワークインターフェイスフィルタ。

        * `Loop` 、 `isatap` 、またはで始まるネットワークインターフェイス `Local`

        デフォルトを上書きするには、設定ファイルに独自のフィルタを記述します。

        ```
        network_interface_filters:
          prefix:
            - dummy
            - lo
          index-1:
            - tun
        ```

        ### カスタムアトリビュート

        [カスタム属性](/docs/data-apis/custom-data/custom-events/collect-custom-attributes/) は、Infrastructureエージェントからのデータに注釈を付けるために使用されるキーと値のペア（他のツールのタグに似ている）です。このメタデータを使用して、フィルターセットを構築し、結果をグループ化し、データに注釈を付けることができます。たとえば、マシンの環境（ステージングまたは本番）、マシンがホストするサービス（ログインサービスなど）、またはそのマシンを担当するチームを示すことができます。このメタデータを使用して、フィルタセットの構築、結果のグループ化、およびデータの注釈付けを行うことができます。たとえば、マシンの環境（ステージングまたは本番）、マシンがホストするサービス（ログインサービスなど）、またはそのマシンを担当するチームを示すことができます。

        からのカスタム属性の例 `newrelic.yml`

        ```
        custom_attributes:
          environment: production
          service: billing
          team: alpha-team
        ```

        これらは強力で便利ですが、データがうまく整理されていなかったり、何らかの形で古くなっている場合は、これらをストリーム化することを検討する必要があります。
      </Collapser>

      <Collapser
        id="k8s-integration"
        title="Kubernetesインテグレーション"
      >
        <Callout
          variant="IMPORTANT"
          title="成長ドライバー"
        >
          * 監視された`pods`と`containers`の数
          * kubeステートメトリクスの収集頻度と数
          * クラスタごとに生成されるログ
        </Callout>

        Kubernetesのような複雑で分散型のシステムが、多くのテレメトリを高速に生成する可能性があることは驚くべきことではありません。 Kubernetesでデータの取り込みを管理するための優れたアプローチがいくつかあります。 K8sデプロイメントでコードとして可観測性を使用している場合、これらは非常に簡単です。 K8の取り込みを減らすことを決定する前に、この`Kubernetes Data Ingest Analysis`ダッシュボードをインストールすることを強くお勧めします。 dashbaordは、この[クイックスタート](https://newrelic.com/instant-observability/infrastructure-integrations-data-analysis/8e31a0ae-81c0-4df0-a119-a0ada9ec16fa)で利用できます。

        ### スクレイプ間隔

        可観測性の目的に応じて、スクレイプ間隔の調整を検討できます。デフォルトは15秒です。現在、Kubernetesクラスターエクスプローラーは45秒ごとにのみ更新されます。 K8sデータの主な用途がKCEの視覚化をサポートすることである場合は、スクレイプ間隔を20秒に変更することを検討してください。 15秒から20秒への変更は、大きな影響を与える可能性があります。 [スクレイプ間隔](/docs/kubernetes-pixie/kubernetes-integration/installation/install-kubernetes-integration-using-helm/#scrape-interval)の管理の詳細については、Helm構成ドキュメントを参照してください。

        ### Kubeステートメトリクス

        Kubernetes cluster explorerで必要なのは、以下のkube state metrics（KSM）のみです。

        ```
        Container data
        Cluster data
        Node data
        Pod data
        Volume data
        API server data*
        Controller manager data*
        ETCD data*
        Scheduler data*

        *Not collected in a managed Kubernetes environment (EKS, GKE, AKS, etc.)
        **Used in the default alert: “ReplicaSet doesn't have desired amount of pods”
        ```

        以下の一部を無効化することをご検討ください。

        ```
        DaemonSet data
        Deployment data
        Endpoint data
        Namespace data
        ReplicaSet data**
        Service data
        StatefulSet data
        ```

        _マニフェストの状態メトリックを更新する例（デプロイメント）_

        ```shell
        [spec]
        [template]
        [spec]
        [containers]
        [name=kube-state-metrics]
        [args]
         #- --collectors=daemonsets
         #- --collectors=deployments
         #- --collectors=endpoints
         #- --collectors=namespaces
         #- --collectors=replicasets
         #- --collectors=services
         #- --collectors=statefulsets
        ```

        _マニフェストの状態メトリックを更新する例（ClusterRole）_

        ```shell
        [rules]
        # - apiGroups: ["extensions", "apps"]
        #   resources:
        #   - daemonsets
        #   verbs: ["list", "watch"]

        # - apiGroups: ["extensions", "apps"]
        #   resources:
        #   - deployments
        #   verbs: ["list", "watch"]

        # - apiGroups: [""]
        #   resources:
        #   - endpoints
        #   verbs: ["list", "watch"]

        # - apiGroups: [""]
        #   resources:
        #   - namespaces
        #   verbs: ["list", "watch"]

        # - apiGroups: ["extensions", "apps"]
        #   resources:
        #   - replicasets
        #   verbs: ["list", "watch"]

        # - apiGroups: [""]
        #   resources:
        #   - services
        #   verbs: ["list", "watch"]

        # - apiGroups: ["apps"]
        #   resources:
        #   - statefulsets
        #   verbs: ["list", "watch"]
        ```

        ### `nri-bundle`チャートの構成`lowDataMode`

        当社のヘルムチャートは、詳細情報をドロップすることを犠牲にして、取り込まれるデータの量を減らすオプションの設定をサポートしています。有効にするには、 `nri-bundle`チャートで`global.lowDataMode`を`true`に設定します。

        `lowDataMode` `nri-bundle`チャートの3つの特定のコンポーネントに影響します。

        1. インフラストラクチャエージェントの間隔を`15` }秒から`30`秒に増やします。
        2. Prometheus OpenMetrics Integrationは、以下のHelmドキュメントに示されているように、いくつかのメトリックを除外します。
        3. ラベルと注釈の詳細はログから削除されます。

        この構成の詳細については、 [Helmドキュメント](/docs/kubernetes-pixie/kubernetes-integration/installation/install-kubernetes-integration-using-helm/#reducedataingest)を参照してください。
      </Collapser>

      <Collapser
        id="on-host-integrations"
        title="オンホストインテグレーション"
      >
        New Relic のオンホスト統合 (略して OHI) は、Postgresql、MySQL、Kafka、RabbitMQ などのサードパーティサービスに対する多様な統合の集合を表します。このドキュメントの範囲内ですべての最適化手法を提供することはできませんが、一般的に適用可能なこれらの手法を提供することは可能です。

        * サンプリングレートの管理

        * コレクションの幅を広げたり狭めたりできるコンフィグの部分を管理する。

        * カスタムクエリを可能にするコンフィグ部分の管理

        * インフラストラクチャーエージェントのカスタム属性は、ホスト上のすべての統合データに適用されるため、管理します。

          いくつかの例を使って説明します。

          ### [PostgreSQLの統合](/docs/infrastructure/host-integrations/host-integrations-list/postgresql-monitoring-integration/#example-postgresSQL-collection-config)

          <Callout
            variant="IMPORTANT"
            title="成長ドライバー"
          >
            * 監視対象テーブル数
            * 監視対象指標数
          </Callout>

          PostgreSQLのオンホスト統合設定では、データ量の管理に役立つこれらの調整可能な設定が提供されています。

        * の間隔を指定します。デフォルトは15s

        * COLLECTION_LIST: 監視するテーブルのリスト (すべて監視する場合はALLを使用)

        * COLLECT_DB_LOCK_METRICS： `dblock`メトリックを収集します

        * PGBOUNCER： `pgbouncer`メトリックを収集します

        * collect_bloat_metrics:ブロートメトリクスを収集する

        * METRICS：メトリックのみを収集するには`true`に設定します

        * インベントリ：インベントリ収集のみを有効にするには、 `true`に設定します

        * CUSTOM_METRICS_CONFIG: カスタムコレクションクエリを含むコンフィグファイル

          _サンプルコンフィグ_

          ```
          integrations:
            - name: nri-postgresql
              env:
                USERNAME: postgres
                PASSWORD: pass
                HOSTNAME: psql-sample.localnet
                PORT: 6432
                DATABASE: postgres

                COLLECT_DB_LOCK_METRICS: false
                COLLECTION_LIST: '{"postgres":{"public":{"pg_table1":["pg_index1","pg_index2"],"pg_table2":[]}}}'
                TIMEOUT:  10
              interval: 15s
              labels:
                env: production
                role: postgresql
              inventory_source: config/postgresql
          ```

          ### [Kafkaとの統合](/docs/infrastructure/host-integrations/host-integrations-list/kafka-monitoring-integration/)

          <Callout
            variant="IMPORTANT"
            title="成長ドライバー"
          >
            * クラスタ内のブローカー数
            * クラスタ内のトピック数
          </Callout>

          Kafkaのオンホスト統合設定では、データ量の管理に役立つ、これらの調整可能な設定が提供されています。

        * の間隔を指定します。デフォルトは15s

        * TOPIC_MODE：収集するトピックの数を決定します。オプションは、 `all` 、 `none` 、 `list` 、または`regex`です。

        * METRICS：メトリックのみを収集するには`true`に設定します

        * インベントリ：インベントリ収集のみを有効にするには、 `true`に設定します

        * TOPIC_LIST。監視するトピック名のJSON配列。topic_mode が list に設定されている場合のみ有効。

        * COLLECT_TOPIC_SIZE：メトリックトピックサイズを収集します。オプションは`true`または`false`で、デフォルトは`false`です。

        * COLLECT_TOPIC_OFFSET：メトリックトピックオフセットを収集します。オプションは`true`または`false`で、デフォルトは`false`です。

          トピック・レベルのメトリクス、特にオフセットの収集にはリソースが必要であり、データ量に影響を与える可能性があることに注意する必要があります。クラスタに新しいKafkaトピックを追加するだけで、クラスタのインジェストが1桁増える可能性は大いにあります。

          ### [MongoDBとの連携](/docs/infrastructure/host-integrations/host-integrations-list/mongodb-monitoring-integration)

          <Callout
            variant="IMPORTANT"
            title="成長ドライバー"
          >
            * 監視対象データベース数
          </Callout>

          MongoDBとの連携では、このような調整可能な設定が用意されており、データ量の管理に役立てることができます。

        * の間隔を指定します。デフォルトは15s

        * METRICS：メトリックのみを収集するには`true`に設定します

        * インベントリ：インベントリ収集のみを有効にするには、 `true`に設定します

        * FILTERS: データベース名とコレクション名の配列のJSONマップ。空の場合、デフォルトはすべてのデータベースとコレクションです。

          使用するオンホスト統合では、デフォルトですべてのデータベースからメトリックを収集する`FILTERS`などのパラメーターに注意することが重要です。これは、監視の優先順位を使用して、収集されたデータを合理化できる領域です。

          _METRICとINVENTORYの間隔が異なる設定例_

          ```
          integrations:
            - name: nri-mongodb
              env:
                METRICS: true
                CLUSTER_NAME: my_cluster
                HOST: localhost
                PORT: 27017
                USERNAME: mongodb_user
                PASSWORD: mongodb_password
              interval: 15s
              labels:
                environment: production

            - name: nri-mongodb
              env:
                INVENTORY: true
                CLUSTER_NAME: my_cluster
                HOST: localhost
                PORT: 27017
                USERNAME: mongodb_user
                PASSWORD: mongodb_password
              interval: 60s
              labels:
                environment: production
              inventory_source: config/mongodb
          ```

          ### [Elasticsearchの統合](/docs/infrastructure/host-integrations/host-integrations-list/elasticsearch-monitoring-integration)

          <Callout
            variant="IMPORTANT"
            title="成長ドライバー"
          >
            * クラスタ内のノード数
            * クラスタ内のインデックス数
          </Callout>

          Elasticsearchとの連携では、このような調整可能な設定が用意されており、データ量の管理に役立てることができます。

        * の間隔を指定します。デフォルトは15s

        * METRICS：メトリックのみを収集するには`true`に設定します

        * インベントリ：インベントリ収集のみを有効にするには、 `true`に設定します

        * COLLECT_INDICES: インデックスを収集するかどうかを示す。

        * COLLECT_PRIMARIES: プライマリーメトリクスを収集するかどうかをシグナリングする。

        * INDICES_REGEX: どのインデックスを収集するかフィルタリングする。

        * MASTER_ONLY: 選出されたマスタのみで、クラスタ・メトリクスを収集します。

          _METRICとINVENTORYの間隔が異なる設定例_

          ```
          integrations:
            - name: nri-elasticsearch
              env:
                METRICS: true
                HOSTNAME: localhost
                PORT: 9200
                USERNAME: elasticsearch_user
                PASSWORD: elasticsearch_password
                REMOTE_MONITORING: true
              interval: 15s
              labels:
                environment: production

            - name: nri-elasticsearch
              env:
                INVENTORY: true
                HOSTNAME: localhost
                PORT: 9200
                USERNAME: elasticsearch_user
                PASSWORD: elasticsearch_password
                CONFIG_PATH: /etc/elasticsearch/elasticsearch.yml
              interval: 60s
              labels:
                environment: production
              inventory_source: config/elasticsearch
          ```

          ### [JMXの統合](/docs/infrastructure/host-integrations/host-integrations-list/jmx-monitoring-integration)

          <Callout
            variant="IMPORTANT"
            title="成長ドライバー"
          >
            * COLLECTION_CONFIGSに記載されている指標
          </Callout>

          JMXの統合は、本質的に汎用的です。これは、任意のJMXインスタンスからメトリクスをスクレイピングすることを可能にします。この統合によって収集されるものについては、十分な量の制御が可能です。一部のエンタープライズ向け New Relic 環境では、JMX メトリクスが収集される全データの中で比較的高い割合を占めています。

          JMX統合は、データ量の管理に役立つこれらの調整可能な設定を提供します。

        * の間隔を指定します。デフォルトは15s

        * METRICS：メトリックのみを収集するには`true`に設定します

        * インベントリ：インベントリ収集のみを有効にするには、 `true`に設定します

        * METRIC_LIMIT: エンティティごとに収集可能なメトリクスの数。この制限を超えた場合、そのエンティティは報告されない。0は制限なしを意味する。

        * LOCAL_ENTITY：ローカル・エンティティのすべてのメトリクスを収集します。localhostを監視するときのみ使用。

        * COLLECTION_FILES: メトリックコレクション定義ファイルへの完全なファイルパスのカンマ区切りリストです。オンホストインストールの場合、デフォルトの JVM メトリックコレクションファイルは、 /etc/newrelic-infra/integrations.d/jvm-metrics.yml にあります。

        * COLLECTION_CONFIG: JSONとしてのメトリクスコレクションの構成。

          取り込まれるデータ量を最も支配するのは、COLLECTION_CONFIGの項目です。スクレイピングしているJMXモデルを理解することは、最適化に役立ちます。

          _JVMメトリクスのためのCOLLECTION_CONFIGの例_

          ```
          COLLECTION_CONFIG='{"collect":[{"domain":"java.lang","event_type":"JVMSample","beans":[{"query":"type=GarbageCollector,name=*","attributes":["CollectionCount","CollectionTime"]},{"query":"type=Memory","attributes":["HeapMemoryUsage.Committed","HeapMemoryUsage.Init","HeapMemoryUsage.Max","HeapMemoryUsage.Used","NonHeapMemoryUsage.Committed","NonHeapMemoryUsage.Init","NonHeapMemoryUsage.Max","NonHeapMemoryUsage.Used"]},{"query":"type=Threading","attributes":["ThreadCount","TotalStartedThreadCount"]},{"query":"type=ClassLoading","attributes":["LoadedClassCount"]},{"query":"type=Compilation","attributes":["TotalCompilationTime"]}]}]}'
          ```

          `NonHeapMemoryUsage.Init`など、その構成から1つのエントリを省略すると、収集されるデータ量全体に具体的な影響があります。

          _Tomcatのメトリクス用COLLECTION_CONFIGの例_

          ```
          COLLECTION_CONFIG={"collect":[{"domain":"Catalina","event_type":"TomcatSample","beans":[{"query":"type=UtilityExecutor","attributes":["completedTaskCount"]}]}]}
          ```

          ### その他のオンホストインテグレーション

          その他にも、収集の最適化に役立つ設定オプションを持つオンホスト統合が多数あります。よく使われるものをいくつか紹介します。

        * [NGINX](/docs/infrastructure/host-integrations/host-integrations-list/nginx/nginx-advanced-config)

        * [MySQL](/docs/infrastructure/host-integrations/host-integrations-list/mySQL/mysql-integration)

        * [Redis](/docs/infrastructure/host-integrations/host-integrations-list/redis-monitoring-integration)

        * [アパッチ](/docs/infrastructure/host-integrations/host-integrations-list/apache-monitoring-integration)

        * [RabbitMQ](/docs/infrastructure/host-integrations/host-integrations-list/rabbitmq-monitoring-integration)

          これは良い [スタート地点](/docs/infrastructure/infrastructure-integrations/get-started/introduction-infrastructure-integrations#on-host) もっと学ぶために。
      </Collapser>

      <Collapser
        id="network-performance-monitoring"
        title="ネットワークパフォーマンスモニタリング（NPM）"
      >
        <Callout
          variant="IMPORTANT"
          title="成長ドライバー"
        >
          * 駆動するモニター機器。

            * ハードコンフィグデバイス
            * ディスカバリーセクションのCIDRスコープ
            * トラップ設定
        </Callout>

        このセクションでは、Kentikの`ktranslate`エージェントに依存するNewRelicのネットワークパフォーマンスモニタリングに焦点を当てます。このエージェントは非常に洗練されており、主要な最適化作業の前に、[高度な構成ドキュメント](/docs/network-performance-monitoring/advanced/advanced-config)を完全に理解することが重要です。

        * mibs_enabled。ktranslate ドッカーイメージがポーリングするすべてのアクティブな MIB の配列です。このリストは、discovery_add_mibs 属性が true の場合、検出時に自動的に生成されます。ここにリストアップされていない MIB は、設定ファイル内のどのデバイスでもポーリングされません。MIB-NAME.tableName構文を使用して、MIBファイル内でSNMPテーブルを直接指定することができます。例：HOST-RESOURCES-MIB.hrProcessorTable.HOST-RESOURCES-MIB.hrProcessorテーブル。

        * user_tags: キーと値のペアの属性で、デバイスにさらにコンテキストを与えます。このレベルのタグは、コンフィギュレーションファイル内の全てのデバイスに適用されます。

        * のデバイスを使用します。流量を監視する機器をリストアップするセクション

        * traps: SNMP トラップを監視する IP およびポートを設定します（デフォルトは 127.0.0.1:1162 です）。

        * 発見：エンドポイントを発見する方法を設定します。このセクションでは、以下のパラメータがスコープを拡大または縮小するために最も効果的です。

          * cidrs:Array of target IP ranges in [CIDR notation](https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing#CIDR_notation).
          * ポートです: SNMPポーリング中にスキャンするターゲットポートの配列。
          * debug：検出中にデバッグレベルのログを有効にするかどうかを示します。デフォルトでは、 `false`
          * default_communities。SNMPポーリング中にスキャンするSNMPv1/v2cコミュニティ文字列の配列。この配列は順番に評価され、ディスカバリーは最初に通過したコミュニティを受け入れます。

          可観測性のニーズに見合う価値を生み出さないデータのフィルタリングをサポートするために、 `global.match_attributes.{}`または`devices.<deviceName>.match_attributes.{}`属性マップを設定できます。

          これにより、New Relicにデータを送信する前に、ktranslateレベルでフィルタリングが提供され、インターフェースなどの監視をきめ細かく制御できるようになります。

          詳細については、 [このページ](https://docs.newrelic.com/docs/network-performance-monitoring/advanced/advanced-config/#match_attributes-attribute)をご覧ください。
      </Collapser>

      <Collapser
        id="log-forwarders"
        title="ログフォワーダー"
      >
        <Callout
          variant="IMPORTANT"
          title="成長ドライバー"
        >
          * ログ転送
          * フォワードログの平均レコードサイズ
        </Callout>

        ログは、通常、独自のルーティングと変換ルールを持つ専用の転送レイヤーを通してログをルーティングするという点で、最も柔軟な遠隔測定ソースの1つを表します。様々なフォワーダがあるので、ここでは最も一般的に使われるものに焦点を当てます。

        * Fluentd
        * Fluentbit
        * New Relic インフラエージェント (Fluentbit 内蔵)
        * Logstash

        フォワーダーは通常、フィルタリングと変換を含むかなり完全な[ルーティングワークフロー](https://docs.fluentd.org/configuration/routing-examples)を提供します。 New Relicのインフラストラクチャエージェントは、不要なログをフィルタリングするための非常に単純なパターンをいくつか提供します。レコードをフィルタリングするための正規表現。 tail、systemd、syslog、およびtcp（フォーマットなしの場合のみ）ソースでのみサポートされます。このフィールドは、Unixシステムのgrep-Eと同じように機能します。たとえば、キャプチャされている特定のファイルについて、次を使用して`WARN`または`ERROR`を含むレコードをフィルタリングできます。

        ```
        - name: only-records-with-warn-and-error
          file: /var/log/logFile.log
          pattern: WARN|ERROR
        ```

        貴重なフィルタリングまたは解析を行うFluentbit用に事前に作成されたFluentd構成がある場合は、それらをNewRelicロギング構成にインポートできます。これを行うには、 `config_file`および`parsers`パラメーターを使用します。 `config_file` ：既存のFluentBit構成ファイルへのパス。ソースが重複していると、NewRelicのログ管理でメッセージが重複します。 `parsers_file` ：既存のFluentBitパーサーファイルへのパス。次のパーサー名は予約されています： `rfc3164` 、 `rfc3164-local`および`rfc5424` 。データパイプラインのログに属性（またはタグ）を挿入する方法と変換を実行する方法を学ぶと、NewRelicドロップルールを使用してダウンストリーム機能をドロップするのに役立ちます。ソースに関するメタデータを使用してログを拡張することにより、バックエンドに何をドロップするかについて、一元化された簡単に元に戻せる決定を行うことができます。少なくとも、次の属性が何らかの形でログに存在することを確認してください。

        * チーム
        * 環境(dev/stage/prod)
        * アプリケーション
        * データセンター
        * ログレベル

        以下は、ルーティングとフィルタリングの詳細なリソースです。

        * [Fluentdの一般的なフィルタとルーティングのパターン](https://docs.fluentd.org/configuration/routing-examples)
        * [Fluentbitデータパイプライン](https://docs.fluentbit.io/manual/concepts/data-pipeline)
        * [New Relic インフラストラクチャエージェントによるログの転送](/docs/logs/forward-logs/forward-your-logs-using-infrastructure-agent/)
      </Collapser>

      <Collapser
        id="prometheus-metrics-sources"
        title="Prometheusのメトリクスソース"
      >
        <Callout
          variant="IMPORTANT"
          title="成長ドライバー"
        >
          * アプリからエクスポートされたメトリクス数
          * リモートライトまたはPOMIで転送されたメトリクス数
        </Callout>

        New Relicは、PrometheusのメトリクスをNRDBに送信するために、主に2つのオプションを提供しています。このドキュメントでは、メトリックの取り込みを管理するためのベストプラクティスは、New Relicによって作成されたこのコンポーネントのため、主にオプション2、Prometheus OpenMetrics Integration (POMI) に焦点を当てることにします。

        ### オプション1： [Prometheus Remote Write](/docs/integrations/prometheus-integrations/install-configure-remote-write/set-your-prometheus-remote-write-integration)

        Prometheusサーバーのスクレイプ設定オプションについては、 [ここに完全に文書化されています。](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config) 。これらの scrape configs は Prometheus サーバーが収集するメトリクスを決定し、 [remote_write](/docs/integrations/prometheus-integrations/install-configure-remote-write/set-your-prometheus-remote-write-integration) パラメータを設定することで、収集したメトリクスを New Relic Metrics API を介して NRDB に書き込むことができるようになります。

        ### オプション 2: [Prometheus OpenMetrics Integration (POMI)](/docs/integrations/prometheus-integrations/install-configure-openmetrics/install-update-or-uninstall-your-prometheus-openmetrics-integration)

        POMIは、動的に発見されたPrometheusのエンドポイントと静的なエンドポイントの両方からメトリクスをスクレイピングするスタンドアローンの統合です。POMI は、このデータを New Relic Metric API 経由で NRDB に送信します。この統合は、現在 Prometheus Server を実行していないお客様にとって理想的です。

        #### POMI：スクレープレーベル

        POMIはデフォルトで "prometheus.io/scrape=true "というラベルまたはアノテーションを含むPrometheusエンドポイントを発見します。クラスタに何が配置されているかによりますが、これは多数のエンドポイントになり、したがって多数のメトリクスが取り込まれることになります。  
        scrape_enabled_labelパラメータをカスタムなもの（例えば "newrelic/scrape"）に変更し、データ摂取が最も重要な場合にはPrometheusエンドポイントに選択的にラベルまたはアノテーションを付けることが提案されています。

        最新のリファレンス設定は、 [nri-prometheus-latest.yaml](https://download.newrelic.com/infrastructure_agent/integrations/kubernetes/nri-prometheus-latest.yaml) を参照してください。

        _POMIコンフィグパラメータ_

        ```
        # Label used to identify scrapable targets. 
        # Defaults to "prometheus.io/scrape"
           scrape_enabled_label: "prometheus.io/scrape"
        ```

        POMIは、デフォルトでノードレベルで公開されているPrometheusのエンドポイントを検出します。これは通常、Kubelet と cAdvisor から来るメトリクスを含みます。

        New Relic Kubernetes Daemonset を実行している場合、POMI が重複したメトリクスを収集しないように require_scrape_enabled_label_for_nodes: true を設定することが重要です。  
        New Relic Kubernetes Daemonset が対象とするエンドポイントの概要は [こちら](https://github.com/newrelic/nri-kubernetes/blob/main/README.md) 。

        #### POMI: ノードのラベルをスクレイプする

        POMIは、デフォルトでノードレベルで公開されているPrometheusのエンドポイントを検出します。これは通常、Kubelet と cAdvisor から来るメトリクスを含みます。

        New Relic Kubernetes Daemonset を実行している場合、POMI が重複したメトリクスを収集しないように require_scrape_enabled_label_for_nodes: true を設定することが重要です。  
        New Relic Kubernetes Daemonset が対象とするエンドポイントの概要は [こちら](https://github.com/newrelic/nri-kubernetes/blob/main/README.md) 。

        _POMIコンフィグパラメーター_

        ```
        # Whether k8s nodes need to be labeled to be scraped or not. 
        # Defaults to false.
          require_scrape_enabled_label_for_nodes: false
        ```

        #### POMI: _nri-kubernetes_と共存する。

        New Relicの[Kubernetes統合](/docs/integrations/kubernetes-integration/get-started/introduction-kubernetes-integration)は、OOTBの[多くのメトリック](/docs/integrations/kubernetes-integration/understand-use-data/find-use-your-kubernetes-data#metrics)を収集しますが、Kubernetesクラスターから利用可能なすべての可能なメトリックを収集するわけではありません。

        POMI構成には、これに似たセクションが表示されます。これにより、NewRelicKubernetes統合が_KubeStateMetrics_からすでに収集しているメトリックのサブセットのメトリック収集が_無効_になります。

        KubeletとcAdvisorの指標が重複しないように`require_scrape_enabled_label_for_node: true`を設定することも非常に重要です。

        _POMIコンフィグパラメーター_

        ```
        transformations:
            - description: "Uncomment if running New Relic Kubernetes Integration"
              ignore_metrics:
                - prefixes:
                  - kube_daemonset_
                  - kube_deployment_
                  - kube_endpoint_
                  - kube_namespace_
                  - kube_node_
                  - kube_persistentvolume_
                  - kube_persistentvolumeclaim_
                  - kube_pod_
                  - kube_replicaset_
                  - kube_service_
                  - kube_statefulset_

        ```

        #### POMI：リクエスト/リミット設定

        POMIを実行するときは、約500kDPMを生成するクラスターに次の[リソース制限](https://kubernetes.io/docs/tasks/configure-pod-container/assign-memory-resource/)を適用することをお勧めします。

        * CPU制限：1コア（1000m）
        * メモリ制限：1Gb 1024（1G）

        CPU と Memory のリソース要求は、POMI がクラスタから十分なリソースを受け取れるよう、妥当な値に設定する必要があります。極端に低い値（例：CPU: 50M）を設定すると、クラスタのリソースが「うるさい隣人」によって消費される可能性があります。

        DPMを決定するためのクエリー例（post-ingest）は、 [こちら](coming_soon) にあります。

        _POMIコンフィグパラメータ_

        ```
        …

        spec:
          serviceAccountName: nri-prometheus
          containers:
          - name: nri-prometheus
            image: newrelic/nri-prometheus:2.2.0
            resources:
              requests:
                memory: 512Mi
                cpu: 500m
              limits:
                memory: 1G
                cpu: 1000m

        …
        ```

        ### POMI：DPMとカーディナリティの推定

        カーディナリティはGBインジェストあたりの請求額とは直接関係ありませんが、New Relicはカーディナリティと1分あたりのデータポイントについて一定のレート制限を維持しています。Prometheus クラスタからカーディナリティと DPM を可視化できることは、非常に重要なことです。

        <Callout variant="tip">
          トライアルおよび有料アカウントには、試用目的で1M DPMおよび1Mカーディナリティの制限がありますが、アカウントに対して最大15M DPMおよび15Mカーディナリティを要求することができます。メトリックレート制限の変更をリクエストするには、New Relic アカウント担当者にお問い合わせください。情報については、この [doc](/docs/data-apis/ingest-apis/metric-api/metric-api-limits-restricted-attributes/) をご覧ください。
        </Callout>

        すでにPrometheus Serverを実行している場合は、POMIやremote_writeを有効にする前に、そこでDPMとカーディナリティの推定を実行することができます。

        _データポイント/分（DPM）_

        レート(prometheus_tsdb_head_samples_appended_total\[10m]) \* 60

        _上位20位までの指標（カーディナリティが最も高いもの）_

        ```
        topk(20, count by (**name**, job)({__name__=~".+"}))
        ```
      </Collapser>

      <Collapser
        id="cloud-integration"
        title="クラウドインテグレーション"
      >
        <Callout
          variant="IMPORTANT"
          title="成長ドライバー"
        >
          * 統合ごとにエクスポートされるメトリクスの数
          * ポーリング頻度(ポーリングベースの統合の場合)
        </Callout>

        New Relicのクラウド統合は、クラウドプロバイダーのAPIからデータを取得します。データは一般的に、AWS CloudWatch、Azure Monitor、GCP Stackdriverなどの監視APIから収集され、インベントリのメタデータは特定のサービスのAPIから収集されます。さらに、私たちの統合は、AWS Kinesisのようなストリーミングサービスを介してプッシュされるストリーミングメトリクスからデータを取得します。

        ### ポーリングAPIベースの統合

        クラウドインテグレーションからのデータをより多くまたはより少なく報告したい場合、あるいはクラウドアカウントのレートやスロットリングの制限に達しないようクラウドプロバイダーのAPIの使用を制御する必要がある場合、構成設定を変更して報告するデータ量を変更することができます。主な制御は次の2つです。

        * [ポーリング周波数の変更](/docs/infrastructure/infrastructure-integrations/cloud-integrations/configure-polling-frequency-data-collection-cloud-integrations/#polling)

        * [データの報告内容の変更](/docs/infrastructure/infrastructure-integrations/cloud-integrations/configure-polling-frequency-data-collection-cloud-integrations/#filter-data)

          投票頻度の変更を希望するビジネス上の理由の例としては、以下のようなものがあります。

        * _課金_:AWS CloudWatchの請求書を管理する必要がある場合、ポーリング頻度を減らすとよいでしょう。これを行う前に、クラウド統合に設定されたアラート条件が、この減少の影響を受けないことを確認してください。

        * _新しいサービス_:新しいサービスや構成を導入する際に、より頻繁にデータを収集したい場合は、一時的にポーリング頻度を上げるとよいでしょう。

          <Callout variant="caution">
            統合のコンフィギュレーション設定を変更すると、アラート条件やチャートトレンドに影響を与える場合があります。
          </Callout>

          詳しくは、 [このドキュメントをご覧ください](/docs/infrastructure/infrastructure-integrations/cloud-integrations/configure-polling-frequency-data-collection-cloud-integrations/) 。

          ### _ストリーミング_ または _プッシュ_ メトリクス

          [ストリーミングサービス](/docs/infrastructure/amazon-integrations/aws-integrations-list/aws-metric-stream/) を介してデータをプッシュするオプションを提供するクラウドインテグレーションが増えてきています。これにより、レイテンシーが大幅に削減されることが証明されています。サンプリングレートが設定できないため、音量をコントロールするのが容易でないという問題も指摘されています。

          _ドロップルール_ は、次のセクションでよく説明します。これらは、ボリュームが大きすぎるストリーミング・メトリクスをフィルタリングするための主要な方法です。しかし、クラウドプロバイダー側でストリーム量をある程度制限することができるものもあります。

          例えばAWSでは、 _条件キー_ から [を使って、CloudWatch\* の名前空間へのアクセスを制限することが可能です](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/iam-cw-condition-keys-namespace.html).

          次のポリシーでは、 _MyCustomNamespace_ という名前のネームスペースでのみメトリクスを公開するようにユーザーを制限します。

          ```
          {
              "Version": "2012-10-17",
              "Statement": {
                  "Effect": "Allow",
                  "Resource": "*",
                  "Action": "cloudwatch:PutMetricData",
                  "Condition": {
                      "StringEquals": {
                          "cloudwatch:namespace": "MyCustomNamespace"
                      }
                  }
              }
          }
          ```

          次のポリシーでは、 _CustomNamespace2_ 以外の任意のネームスペースでメトリクスを公開することができます。

          ```
          {
              "Version": "2012-10-17",
              "Statement": [
                  {
                      "Effect": "Allow",
                      "Resource": "*",
                      "Action": "cloudwatch:PutMetricData"
                  },
                  {
                      "Effect": "Deny",
                      "Resource": "*",
                      "Action": "cloudwatch:PutMetricData",
                      "Condition": {
                          "StringEquals": {
                              "cloudwatch:namespace": "CustomNamespace2"
                          }
                      }
                  }
              ]
          }
          ```
      </Collapser>
    </CollapserGroup>
  </Collapser>

  <Collapser
    id="optimization-with-drop-rules"
    title="ドロップルールによる最適化"
  >
    _クエリすれば落とすことができる_

    ドロップフィルターのルールは、いくつかの重要な目標を達成するのに役立ちます。

    * お客様のアカウントに関連するログのみを保存することで、コストを削減できます。

    * 個人を特定できる情報（PII）を削除することで、プライバシーとセキュリティを保護します。

    * 無関係なイベントや属性を削除して、ノイズを減らす。

      _注意事項_

      ドロップルールを作成する際には、設定した条件に合致するデータをルールが正確に識別し、廃棄することに責任を持つ必要があります。また、New Relic に開示するデータだけでなく、ルールを監視する責任もあります。常にクエリのテストと再テストを行い、ドロップルールがインストールされた後は、意図したとおりに動作することを確認します。ドロップ前後のデータを監視するためのダッシュボードを作成すると効果的です。

      <CollapserGroup>
        <Collapser
          id="logs"
          title="ログ"
        >
          すべての New Relic ドロップルールは、同じバックエンドデータモデルと API によって実装されています。しかし、New Relic のログ管理は、ドロップルールを非常に簡単に作成および監視できる強力な UI を提供します。

          遠隔測定の優先順位付けに関する前回のセクションでは、特定のデータを非推奨にする方法を示す演習を行いました。この例をもう一度見てみましょう。

          ```
          Omit debug logs (knowing they can be turned on if there is an issue) (saves 5%)
          ```

          #### 方法1： [Log UI](/docs/logs/ui-data/drop-data-drop-filter-rules/)

          * ログUIでフィルターを使用して、気になるログを特定します。 `level: DEBUG`
          * 落としたいログが見つかるか確認する
          * `level:debug`や`log_level:Debug`などの代替構文を確認してください。これらのバリエーションは一般的です。
          * _Manage Data_ で _Drop filters_ をクリックし、「Drop Debug Logs」という名前のフィルタを作成し、有効にします。
          * ルールの動作を確認する

          #### 方法2: [弊社のNerdGraph APIを利用する。](/docs/data-apis/manage-data/drop-data-using-nerdgraph/)

          * 関連するNRQLクエリを作成します： `SELECT count(*) FROM Log WHERE `レベル` = 'DEBUG'`
          * 落としたいログが見つかるか確認する
          * 属性名と値のバリエーションを確認する（Debug vs DEBUG）
          * 以下のNerdGraph文を実行し、動作することを確認します。

          ```
          mutation {
              nrqlDropRulesCreate(accountId: YOUR_ACCOUNT_ID, rules: [
                  {
                      action: DROP_DATA
                      nrql: "SELECT * FROM Log WHERE `level` = 'DEBUG'"
                      description: "Drops DEBUG logs.  Disable if needed for troubleshooting."
                  }
              ])
              {
                  successes { id }
                  failures {
                      submitted { nrql }
                      error { reason description }
                  }
              }
          }
          ```
        </Collapser>

        <Collapser
          id="process-samples"
          title="プロセスサンプル"
        >
          推奨事項を実装しましょう： `Drop process sample data in DEV environments` 。

          * 関連するクエリを作成します：'SELECT \* FROM ProcessSample WHERE `env` ='DEV''

          * ドロップしたいプロセスサンプルが見つかることを確認する。

          * `env` `ENV`や `Environment`

          * `Dev`などのさまざまな`DEV`を確認してください `Development`

          * NerdGraph APIを使用して、以下のステートメントを実行し、動作を確認してください。

            ```
            mutation {
                nrqlDropRulesCreate(accountId: YOUR_ACCOUNT_ID, rules: [
                    {
                        action: DROP_DATA
                        nrql: "SELECT * FROM ProcessSample WHERE `env` = 'DEV'"
                        description: "Drops ProcessSample from development environments"
                    }
                ])
                {
                    successes { id }
                    failures {
                        submitted { nrql }
                        error { reason description }
                    }
                }
            }
            ```
        </Collapser>

        <Collapser
          id="cloud-metrics"
          title="クラウドメトリクス"
        >
          場合によっては、冗長なカバレッジを持つデータを節約することができます。例えば、AWS RDS統合とNew Relicオンホスト統合を実行している環境では、重複するメトリクスを捨てることができるかもしれません。

          手っ取り早く調べるには、次のようなクエリを実行します。

          ```
          FROM Metric select count(*) where metricName like 'aws.rds%' facet metricName limit max
          ```

          これにより、パターンに一致するすべてのmetricNamesが表示されます。

          結果から、パターン`aws.rds.cpu%`のメトリックが大量にあることがわかります。それらのための他の計装があるので、それらを落としましょう。

          * 該当するクエリを作成します。'FROM Metric select \* where metricName like 'aws.rds.cpu%' facet metricName limit max since 1 day ago'
          * ドロップしたいプロセスサンプルが見つかることを確認する。
          * NerdGraph APIを使用して、以下の文を実行し、動作することを確認する。

          ```
          mutation {
              nrqlDropRulesCreate(accountId: YOUR_ACCOUNT_ID, rules: [
                  {
                      action: DROP_DATA
                      nrql: "FROM Metric select * where metricName like 'aws.rds.cpu%' facet metricName limit max since 1 day ago"
                      description: "Drops rds cpu related metrics"
                  }
              ])
              {
                  successes { id }
                  failures {
                      submitted { nrql }
                      error { reason description }
                  }
              }
          }
          ```
        </Collapser>

        <Collapser
          id="drop-specific-attributes"
          title="特定の属性を削除する"
        >
          ドロップルールの強力な点の1つは、特定の属性をドロップするが、残りのデータはそのまま維持するルールを構成できることです。これを使用して、NRDBからプライベートデータを削除したり、過度に大きな属性を削除したりします。たとえば、ログレコード内のスタックトレースまたはJSONの大きなチャンクは、非常に大きくなる場合があります。

          これらのドロップルールを設定するには、_アクション_フィールドを&#x7B; `DROP_DATA` }ではなく`DROP_ATTRIBUTES`に変更します。

          ```
          mutation {
              nrqlDropRulesCreate(accountId: YOUR_ACCOUNT_ID, rules: [
                  {
                      action: DROP_ATTRIBUTES
                      nrql: "SELECT stack_trace, json_data FROM Log where appName='myApp'"
                      description: "Drops large fields from logs for myApp"
                  }
              ])
              {
                  successes { id }
                  failures {
                      submitted { nrql }
                      error { reason description }
                  }
              }
          }
          ```
        </Collapser>

        <Collapser
          id="drop-random-sample-of-events"
          title="イベントのランダムサンプルをドロップします"
        >
          <Callout variant="caution">
            このアプローチは慎重に使用し、他に選択肢がない状況でのみ使用してください。これは、データから作成された統計的推測を変更する可能性があるためです。ただし、サンプルサイズが大きいイベントの場合、結果を理解している限り、データの一部のみを使用できます。
          </Callout>

          この例では、特定のトレースIDの相対的な分布を利用して、ランダムサンプリングを概算します。 `rlike`演算子を使用して、スパンの`trace.id`属性の先頭の値を確認できます。

          次の例では、スパンの約25％をドロップできます。

          ```
          SELECT * FROM Span WHERE trace.id rlike r'^[0-3].*' and appName = 'myApp'
          ```

          便利な表現は次のとおりです。

          * `^0.*` 約6.25％
          * `^[0-1].*` 約12.5％
          * `^[0-2].*` 約18.75％
          * `^[0-3].*` 約25.0％

          完全な突然変異の例を参照してください。

          ```
          mutation {
              nrqlDropRulesCreate(accountId: YOUR_ACCOUNT_ID, rules: [
                  {
                      action: DROP_ATTRIBUTES
                      nrql: "SELECT * FROM Span WHERE trace.id rlike r'^[0-3].*' and appName = 'myApp'"
                      description: "Drops approximately 25% of spans for myApp"
                  }
              ])
              {
                  successes { id }
                  failures {
                      submitted { nrql }
                      error { reason description }
                  }
              }
          }
          ```
        </Collapser>

        <Collapser
          id="other-events-and-metrics"
          title="その他のイベントと指標"
        >
          NRDBの他のイベントやメトリックにこれらのテクニックを使用するために必要な知識は、前述の例ですべてわかるはずです。クエリーができれば、それをドロップすることができる。ドロップルールのクエリを構成する正確な方法について質問がある場合は、New Relic に連絡してください。
        </Collapser>
      </CollapserGroup>
  </Collapser>
</CollapserGroup>

## エクササイズ [#exercise]

次の質問に答えることで、最適化計画を作成して実行する能力に自信をつけることができます。 `Baselining`セクションの[データ取り込みベースライン](/docs/new-relic-solutions/observability-maturity/operational-efficiency/dg-baselining#install-dashboard)および[データ取り込みエンティティの内訳](http://localhost:8000/docs/new-relic-solutions/observability-maturity/operational-efficiency/dg-baselining#install-entity-breakdown-dashboard)ダッシュボードを使用することをお勧めします。説明されているようにこれらのダッシュボードをインストールし、これらの質問のうちどれだけに答えられるかを確認してください。

| 質問                                                                                                                                                                                                                                                                               |
| -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| この組織の取り込みを月に少なくとも5％削減できる3つのドロップルールを表示しますか？ドロップルールのnerdgraph構文を応答に含めます。                                                                                                                                                                                                           |
| この組織の取り込みを月に少なくとも5％削減するために実装できる、3つのインストルメンテーション構成の変更を提案しますか？応答に構成スニペットを含めます。                                                                                                                                                                                                     |
| K8sモニタリングからのデータ量を減らすためにできる3つのことは何ですか？どのくらいのデータ削減を達成できますか？この削減の潜在的なトレードオフは何ですか（つまり、実質的な可観測性が失われる可能性があります）？                                                                                                                                                                        |
| 1. Data Governance Baselineダッシュボードを使用して、大量のログデータをNewRelicに送信しているアカウントを特定します。<br/> 2.アカウントのドロップダウンメニューからそのアカウントを見つけて選択します。<br/> 3.アカウントの**ログ**ページに移動し、左側のメニューから**パターン**を選択します。<br/> 4.表示されたログパターンを確認し、値の低いログパターンの例をいくつか示します。何がそれらを低い価値にしているのですか？これらのログを削除することで、どれだけの合計削減を達成できますか？ |
| この組織の全体的な分析に基づいて、テレメトリとは何が十分に活用されていませんか？                                                                                                                                                                                                                                         |

## 結論 [#conclusion]

プロセスセクションでは、テレメトリを特定の可観測性値の推進要因または目的に関連付ける方法を示しました。これにより、アカウントの取り込みを最適化するという難しい決定がいくらか簡単になります。目標を保護しながら摂取を最適化する高レベルの[最適化計画](http://localhost:8000/docs/new-relic-solutions/observability-maturity/operational-efficiency/dg-optimizing#develop-plan)を作成する方法を学びました。最後に、構成およびドロップルールベースの取り込み最適化のための[豊富なレシピセット](http://localhost:8000/docs/new-relic-solutions/observability-maturity/operational-efficiency/dg-optimizing#use-reduction-techniques)が紹介されました。